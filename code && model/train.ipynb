{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"Description:\n",
    "The train.py is to build your CNN model, train the model, and save it for later evaluation(marking)\n",
    "This is just a simple template, you feel free to change it according to your own style.\n",
    "However, you must make sure:\n",
    "1. Your own model is saved to the directory \"model\" and named as \"model.h5\"\n",
    "2. The \"test.py\" must work properly with your model, this will be used by tutors for marking.\n",
    "3. If you have added any extra pre-processing steps, please make sure you also implement them in \"test.py\" so that they can later be applied to test images.\n",
    "\n",
    "Â©2019 Created by Yiming Peng and Bing Xue\n",
    "\"\"\"\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, MaxPooling2D,Flatten,Activation,ZeroPadding2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds to ensure the reproducible results\n",
    "SEED = 309\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "\n",
    "# some constants\n",
    "DATA_PATH = \"/home/fanbaiw/2019/comp 309/project/Train_data_2019/Train_data\"\n",
    "IMAGE_SIZE_TUPLE = (300,300)\n",
    "IMAGE_SIZE = 300\n",
    "BATCH_SIZE= 9 # how many images process at one time, the less the better?  from 16 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    datagen = ImageDataGenerator(rotation_range=40, #data pre process\n",
    "        rescale=1. / 255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2)\n",
    "\n",
    "    train = datagen.flow_from_directory(DATA_PATH, target_size= IMAGE_SIZE_TUPLE,\n",
    "                                                      classes=['cherry', 'strawberry', 'tomato'], batch_size = BATCH_SIZE ,\n",
    "                                                      class_mode='categorical', subset='training')\n",
    "\n",
    "    validate = datagen.flow_from_directory(DATA_PATH, target_size= IMAGE_SIZE_TUPLE,\n",
    "                                                      classes=['cherry', 'strawberry', 'tomato'], batch_size = BATCH_SIZE ,\n",
    "                                                      class_mode='categorical', subset='validation')\n",
    "\n",
    "    return train, validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_MLP():\n",
    "   model = Sequential()\n",
    "   model.add(Flatten(input_shape=(300, 300, 3)))\n",
    "   model.add(Dense(64, activation='relu'))\n",
    "   model.add(Dropout(0.5))\n",
    "   model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "   model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model():\n",
    "    \"\"\"\n",
    "    Construct the CNN model.\n",
    "    ***\n",
    "        Please add your model implementation here, and don't forget compile the model\n",
    "        E.g., model.compile(loss='categorical_crossentropy',\n",
    "                            optimizer='sgd',\n",
    "                            metrics=['accuracy'])\n",
    "        NOTE, You must include 'accuracy' in as one of your metrics, which will be used for marking later.\n",
    "    ***\n",
    "    :return: model: the initial CNN model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Conv2D(filters,kernel_size,inputshape)\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(IMAGE_SIZE, IMAGE_SIZE,3))) \n",
    "    model.add(Activation('relu'))   #Activation function\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2))) # max pooling layer\n",
    "    \n",
    "    #---------------------------------Convolutional Layer\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    #-------------------------------Flatten Layer\n",
    "    \n",
    "    model.add(Flatten())  \n",
    "    #-------------------------------Dense Layer\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    #-------------------------------- complie the model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = 'sgd',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train, validate):\n",
    "    \"\"\"\n",
    "    Train the CNN model\n",
    "    ***\n",
    "        Please add your training implementation here, including pre-processing and training\n",
    "    ***\n",
    "    :param model: the initial CNN model\n",
    "    :return:model:   the trained CNN model\n",
    "    \"\"\"\n",
    "#     from time import time\n",
    "#     from keras.callbacks import TensorBoard\n",
    "#     tb = TensorBoard(log_dir = './logs2{}'.format(time()), \n",
    "#                      write_graph = True, write_grads = True, write_images = True)\n",
    "    \n",
    "    model.fit_generator(train,steps_per_epoch=2000,validation_data=validate,epochs=70) #callbacks=[tb])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    \"\"\"\n",
    "    Save the keras model for later evaluation\n",
    "    :param model: the trained CNN model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # ***\n",
    "    #   Please remove the comment to enable model save.\n",
    "    #   However, it will overwrite the baseline model we provided.\n",
    "    # ***\n",
    "    print(\"Model Saved Successfully.\")\n",
    "    model.save(\"model/\" + \"CNNF\" + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2019-10-29 22:38:13.423767\n",
      "Found 2622 images belonging to 3 classes.\n",
      "Found 654 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1029 22:38:13.650537 140340229248832 deprecation.py:506] From /usr/pkg/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "2000/2000 [==============================] - 251s 126ms/step - loss: 1.1933 - acc: 0.3674 - val_loss: 1.0950 - val_acc: 0.3685\n",
      "Epoch 2/70\n",
      "2000/2000 [==============================] - 245s 122ms/step - loss: 1.0960 - acc: 0.3689 - val_loss: 1.0954 - val_acc: 0.3685\n",
      "Epoch 3/70\n",
      "2000/2000 [==============================] - 253s 127ms/step - loss: 1.0960 - acc: 0.3688 - val_loss: 1.0956 - val_acc: 0.3685\n",
      "Epoch 4/70\n",
      "1694/2000 [========================>.....] - ETA: 37s - loss: 1.0957 - acc: 0.3696"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(\"Start: {}\".format(start_time))\n",
    "    x,y = load_data()\n",
    "    #model = construct_model()\n",
    "    model = construct_MLP()\n",
    "    trained_model = train_model(model,x,y)\n",
    "    end_time = datetime.datetime.now()\n",
    "    execution_time = (end_time - start_time).total_seconds()\n",
    "    print(\"Time taken: {}\".format(execution_time))\n",
    "    save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
